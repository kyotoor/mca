{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5617f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ff3a82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape : (494019, 42)\n"
     ]
    }
   ],
   "source": [
    "# Data read and shuffle\n",
    "data_path = './data/kddcup.data_10_percent_shuffled'\n",
    "if os.path.exists(data_path) == False:\n",
    "    print(\"Creating new shuffled data....\")\n",
    "    data = pd.read_csv('./data/kddcup.data_10_percent')\n",
    "    data = data.sample(frac = 1)\n",
    "    data.to_csv(data_path, header=False, index=False)\n",
    "else:\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "data = data.to_numpy()\n",
    "print(\"Data shape :\" , data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3489c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smurf.', 'normal.', 'neptune.', 'nmap.', 'warezclient.', 'teardrop.', 'satan.', 'back.', 'pod.', 'portsweep.', 'ipsweep.', 'guess_passwd.', 'perl.', 'land.', 'rootkit.', 'warezmaster.', 'buffer_overflow.', 'imap.', 'ftp_write.', 'multihop.', 'loadmodule.', 'spy.', 'phf.']\n"
     ]
    }
   ],
   "source": [
    "# visualize the labels\n",
    "labels = []\n",
    "for i in range(0, data.shape[0], 1):\n",
    "    if data[i, 41] not in labels:\n",
    "        labels.append(data[i, 41])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5773b606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of normal (benign) data : 97277\n"
     ]
    }
   ],
   "source": [
    "# Count the amount of normal(benign) traffic\n",
    "def count(string):\n",
    "    count = 0\n",
    "    for i in range(0, data.shape[0], 1):\n",
    "        if data[i, 41] == string:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "print('Amount of normal (benign) data :', count(\"normal.\"))\n",
    "# amount of data is diffetent from original paper. Why??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "129c7a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (normal only) : (97277, 42)\n"
     ]
    }
   ],
   "source": [
    "# Pick the normal (benign) traffic\n",
    "def pick(string):\n",
    "    data_target = data[0:count(string), :].copy()\n",
    "    index = 0\n",
    "    for i in range(0, data.shape[0], 1):\n",
    "        if data[i, 41] == string:\n",
    "            data_target[index, :] = data[i, :].copy()\n",
    "            index = index + 1\n",
    "    return data_target\n",
    "\n",
    "data_normal = pick('normal.')\n",
    "\n",
    "print(\"Data shape (normal only) :\", data_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99256f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick the continuous features :  (97277, 32)\n"
     ]
    }
   ],
   "source": [
    "# Pick the continuous features\n",
    "def reduct(data):\n",
    "    data_target = np.delete(data, [1, 2, 3, 6, 7, 11, 19, 20, 21, 41], axis = 1) \n",
    "    #7 and 19 are the features which var = 0, if we include this features normalization would be impossible.\n",
    "    data_target = data_target.astype('float32')\n",
    "    return data_target\n",
    "\n",
    "data_normal_reducted = reduct(data_normal)\n",
    "print(\"Pick the continuous features : \", data_normal_reducted.shape)\n",
    "\n",
    "# Room to improve and fix...\n",
    "# Cannot understand which 32 features should I select\n",
    "# In the paper \"the TAMs of the different types of traffic records are generated using 32 continuous features.\"\"\n",
    "# Refer this https://kdd.ics.uci.edu/databases/kddcup99/kddcup.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e317d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "def normalization(df):\n",
    "    df_norm = (df - df.mean(axis= 0)) / df.std(ddof = 0, axis = 0)\n",
    "    return df_norm, df.mean(axis= 0), df.std(ddof = 0, axis = 0) # normalized data, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d53cd5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of samples : 97277\n",
      "coordinate : (496, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cartesian coordinate\n",
    "area_length = data_normal_reducted.shape[1]\n",
    "amount = count('normal.')\n",
    "print(\"amount of samples :\", amount)\n",
    "\n",
    "cov_length = int(1/2 * (1 + (area_length - 1)) * (area_length - 1))\n",
    "coordinate = np.zeros((cov_length, 2), \"int32\")\n",
    "print(\"coordinate :\", coordinate.shape)\n",
    "index = 0\n",
    "for j in range(1, area_length, 1):\n",
    "    for k in range(j, area_length, 1):\n",
    "        coordinate[index] = np.array([k, j-1])\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ab14220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAM lower\n",
    "def tam_lower(data):\n",
    "    tam = np.zeros((data.shape[0], cov_length),  \"float32\")\n",
    "    for i in range(0, data.shape[0], 1):\n",
    "        for j in range(0, cov_length, 1):\n",
    "            tam[i, j] = data[i, coordinate[j, 0]] * data[i, coordinate[j, 1]] / 2\n",
    "    return tam\n",
    "\n",
    "# tam = tam_lower(data_normal_reducted)\n",
    "# print(\"TAM shape:\", tam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d07dfe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc Covariance of TAM using lower TAM.\n",
    "def covariance(tam, save_name):\n",
    "    ave_tam = np.average(tam, axis = 0)\n",
    "    #print('average of TAM :', ave_tam.shape)\n",
    "    sum_tam = np.zeros((cov_length, cov_length), \"float32\")\n",
    "    flag_tam = np.zeros((cov_length, cov_length), \"int8\")\n",
    "    num_path = \"./out_num/\" + save_name\n",
    "\n",
    "    if os.path.exists(num_path) == False:\n",
    "        \"\"\"\n",
    "        for jk in range(0, cov_length, 1):\n",
    "            for lv in range(0, cov_length, 1):\n",
    "                if flag_tam[jk, lv] == 0:\n",
    "                    for n in range(0, tam.shape[0], 1):\n",
    "                        sum_tam[jk, lv] = sum_tam[jk, lv] + ((tam[n, jk] - ave_tam[jk]) * (tam[n, lv] - ave_tam[lv]))\n",
    "                    flag_tam[lv, jk] = 1\n",
    "                else:\n",
    "                    sum_tam[jk, lv] = flag_tam[lv, jk]\n",
    "\n",
    "        cov = sum_tam * (1 / (tam.shape[0] - 1))\n",
    "        \"\"\"\n",
    "        cov_sum = np.zeros((tam.shape[1], tam.shape[1]), 'float32')\n",
    "        for i in range(0, 10, 1):\n",
    "            n = int(tam.shape[0] / 10)\n",
    "            cov_sum = cov_sum + np.cov(tam[i*n:(i+1)*n, :].T)\n",
    "        cov = cov_sum / 10\n",
    "        #print('Cov shape :', cov.shape)\n",
    "        np.save(num_path, cov)\n",
    "\n",
    "    else :\n",
    "        cov = np.load(num_path)\n",
    "\n",
    "    return cov\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ab7f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the system\n",
    "def evaluation(labels, alpha, ave_normal, std_normal, ave_tam, start, end, mean, std):\n",
    "    evaluate = np.zeros((len(labels), len(alpha)))\n",
    "    \n",
    "    # Evaluate all the sample belonging to labels\n",
    "    for i in range(0, len(labels), 1):\n",
    "        data = pick(labels[i])\n",
    "        data = data[:100, :] # cut\n",
    "        data_reducted = reduct(data)\n",
    "        if labels[i] == \"normal.\":\n",
    "            data_reducted = data_reducted[start:end]\n",
    "        \n",
    "        # each labels\n",
    "        for j in range(0, data_reducted.shape[0], 1):\n",
    "            observed = data_reducted[j]\n",
    "            observed = (observed - mean) / std\n",
    "            tam_observed = np.zeros((cov_length,))\n",
    "            \n",
    "            # each samples\n",
    "            for k in range(0, cov_length, 1):\n",
    "                tam_observed[k] = observed[coordinate[k, 0]] * observed[coordinate[k, 1]]  / 2\n",
    "            \n",
    "            # print(tam_observed)\n",
    "            md_observed = distance.mahalanobis(tam_observed, ave_tam, cov_inv)\n",
    "            # md_observed = np.dot(np.dot((tam_observed - ave_tam).T, cov_inv), (tam_observed - ave_tam)) ** (1/2)\n",
    "            # print(md_observed)\n",
    "            \n",
    "            # each alpha\n",
    "            for l in range(0, len(alpha), 1):\n",
    "                if labels[i] == 'normal.':\n",
    "                    if ((ave_normal - (std_normal * alpha[l])) <= md_observed) and (md_observed <= (ave_normal + (std_normal * alpha[l]))):\n",
    "                        evaluate[i, l] = evaluate[i, l] + 0.\n",
    "                    else :\n",
    "                        evaluate[i, l] = evaluate[i, l] + 1. # 0.       \n",
    "                else:\n",
    "                    if ((ave_normal - (std_normal * alpha[l])) <= md_observed) and (md_observed <= (ave_normal + (std_normal * alpha[l]))):\n",
    "                        evaluate[i, l] = evaluate[i, l] + 0. # 0.\n",
    "                    else :\n",
    "                        evaluate[i, l] = evaluate[i, l] + 1.\n",
    "                        \n",
    "        evaluate[i, :] = evaluate[i, :] / float(data_reducted.shape[0])\n",
    "        \n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3e3e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ...\n"
     ]
    }
   ],
   "source": [
    "# Evaluate by using 10 Cross Validation\n",
    "k = 10\n",
    "eva_labels = ['normal.', 'teardrop.', 'smurf.', 'pod.', 'neptune.', 'land.', 'back.']\n",
    "alpha = [1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "evaluate = np.zeros((10, len(eva_labels), len(alpha)))\n",
    "\n",
    "for i in range(0, k, 1):\n",
    "    # Divide train data & validation data\n",
    "    start = i * int(amount / k)\n",
    "    end = (i + 1) * int(amount / k)\n",
    "    train_data = np.concatenate([data_normal_reducted[:start, :], data_normal_reducted[end:, :]])\n",
    "    train_data_normalized, mean, std = normalization(train_data)\n",
    "    train_tam = tam_lower(train_data_normalized)\n",
    "    ave_tam = np.average(train_tam, axis = 0)\n",
    "    #val_tam = tam[start:end, :]\n",
    "    \n",
    "    # Calc cov from train data\n",
    "    # print(i, \": Calc COV. takes time...\")\n",
    "    cov = covariance(train_tam, str(i) + '_norm.npy')\n",
    "    \n",
    "    # Clac MD distance\n",
    "    cov_inv = np.linalg.pinv(cov)\n",
    "    md = np.zeros((train_tam.shape[0], ))\n",
    "    for j in range(0, train_tam.shape[0], 1):\n",
    "        md[j] = distance.mahalanobis(train_tam[j], ave_tam, cov_inv)\n",
    "        # md[j] = np.dot(np.dot((train_tam[j] - ave_tam).T, cov_inv), (train_tam[j] - ave_tam)) ** (1/2)\n",
    "    ave_normal = np.average(md, axis = 0)\n",
    "    std_normal = np.std(md, axis = 0, ddof=1)\n",
    "    #print(var_normal)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"Evaluating ...\")\n",
    "    result = evaluation(eva_labels, alpha, ave_normal, std_normal, ave_tam, start, end, mean, std)\n",
    "    evaluate[i] =  result\n",
    "    break\n",
    "\n",
    "out = np.average(evaluate, axis = 0)\n",
    "\n",
    "np.save('./results/evaluate.npy', evaluate)\n",
    "np.save('./results/out.npy', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40f23944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   2.   1.   1.   1.]\n",
      " [ 63.  57.  47.  39.  35.]\n",
      " [100. 100. 100. 100. 100.]\n",
      " [ 55.  55.  46.  24.  16.]\n",
      " [100. 100. 100. 100. 100.]\n",
      " [100. 100. 100. 100. 100.]\n",
      " [100. 100. 100. 100. 100.]]\n"
     ]
    }
   ],
   "source": [
    "#np.set_printoptions(precision=3, floatmode='fixed', suppress=True)\n",
    "print(out*10*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
